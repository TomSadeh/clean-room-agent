[task]
id = "RT-010"
description = "Refactor the LLM client layer to extract the Ollama-specific transport into a separate backend class, leaving LLMClient as a thin interface that delegates to a configurable backend. This prepares for adding vLLM and remote API backends in Phase 4"
task_type = "refactor"

[context_requirements]
must_contain_files = [
  "src/clean_room_agent/llm/client.py",
  "src/clean_room_agent/llm/router.py",
]

should_contain_files = [
  "src/clean_room_agent/llm/enrichment.py",
  "src/clean_room_agent/retrieval/pipeline.py",
  "src/clean_room_agent/config.py",
]

must_not_contain = [
  "src/clean_room_agent/indexer/*",
  "src/clean_room_agent/knowledge_base/*",
  "src/clean_room_agent/parsers/*",
  "src/clean_room_agent/extractors/*",
]

must_contain_information = [
  "Full source of LLMClient class (the base transport)",
  "Full source of LoggedLLMClient (wrapper pattern)",
  "Full source of EnvironmentLLMClient (wrapper pattern)",
  "ModelRouter class and how it resolves model configs",
  "How pipeline.py creates and uses LLM clients",
  "How enrichment.py creates and uses LLM clients",
  "ModelConfig dataclass (what configuration an LLM client needs)",
]

budget_range = [45, 85]

[routing_notes]
reasoning = "Major refactoring: needs broad scope to find all consumers of LLMClient + deep precision on the client module itself and all call sites."
