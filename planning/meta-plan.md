# Clean Room Agent Meta-Plan

## Purpose

This document defines the top-level execution order and ownership boundaries across phases.

---

## Phase Split

1. **Phase 1: Knowledge Base + Indexer Build**
- Build deterministic indexing, all three DB schemas (curated, raw, session), parsers, dependency graph, git metadata, and query API.
- Creates the connection factory and all schema definitions. Populates curated DB via indexing; logs indexing run metadata to raw DB.
- Gate: `cra index` and data/query integrity are stable across all three DB schemas.

2. **Phase 2: Retrieval Pipeline Build**
- Build the N-stage retrieval pipeline: stage protocol, pipeline runner, task analysis, budget enforcement, context assembly, and `cra retrieve`. MVP ships with two retrieval stages (Scope, Precision); the architecture supports adding stages without structural changes.
- Gate: retrieval runs end-to-end and output is budget-compliant and actionable.

3. **Phase 3: Agent Harness Build**
- Build `cra solve`: prompting, generation, parse/apply/validate loop, and retries. `cra solve` calls retrieval internally (in-memory handoff). Baseline mode is out of scope for the active plan.
- Gate: `cra solve` works end-to-end.

---

## Hard Boundaries

- Phases 1-3 are **build phases**.
- Formal validation and benchmark claims are out of scope for the active plan.

---

## Dependency Order

Phase 1 -> Phase 2 -> Phase 3

No phase should pull validation gates from a later phase.

---

## Cross-Cutting: Three-Database Architecture

Three separate SQLite files with independent WAL journals, backups, and lifecycles:

- **Curated DB** (`curated.sqlite`) - the "clean room" the model reads from. Verified signals only.
- **Raw DB** (`raw.sqlite`) - append-only log of all activity. Training corpus and analysis source.
- **Session DB** (`session_<task_id>.sqlite`) - ephemeral per-task working memory. Created per run, discarded after.

### Ownership Table

| Phase | Curated DB | Raw DB | Session DB |
|-------|-----------|--------|------------|
| Phase 1 | **Creates schema + populates** (indexing) | **Creates schema** + logs index run metadata | **Defines schema only** (no per-task DB files created) |
| Phase 2 | Read-only (query API, enforced via read-only connection mode) | Append retrieval decisions | **Creates** per-task, writes retrieval state |
| Phase 3 | No direct access (curated preflight happens in Phase 2 retrieval entrypoint) | Append all attempts, results, LLM outputs | Inherits from Phase 2, writes retry context, **closes** |

### Key Constraints

- Phases 2 and 3 never write to curated DB.
- Raw->curated derivation is explicitly not automated in the active plan.
- Phase 2 and Phase 3 share one session DB per task run. Phase 2 creates it and returns an explicit session handle. Phase 3 takes ownership of that handle and closes it.
- Task IDs are generated by `cra solve` at startup (UUID4) and passed to Phase 2 retrieval.
- Connection factory: `get_connection(role, task_id=None, read_only=False)` is the single point of DB management. Phase 2 curated reads use `read_only=True`.
- `cra enrich` is required before `cra retrieve` and `cra solve`. Phase 2 scope expansion depends on `file_metadata`. Single mode (pipeline) â€” no `--mode` flag needed until a second mode exists.
- Token budgets are coordinated via a shared `BudgetConfig` created at `cra solve` startup and passed to Phase 2.
- Phase 3 may request additional context only via an explicit refinement handoff back to Phase 2. Phase 3 never performs direct curated retrieval.
- Refinement loops are bounded (`max_refinement_loops` from caller config) and require structured evidence (`insufficient_context` classification with concrete missing items).
- **Refinement session contract**: Phase 3 writes `"refinement_request"` (serialized `RefinementRequest`) and `"attempt_summary"` to session DB, then calls Phase 2 re-entry. Phase 2 reads `"refinement_request"` and `"final_context"` (its own prior output) from session DB to expand context. See Phase 2 Step 6 and Phase 3 Step 6 for the full protocol.
- `.clean_room/` must be added to the target repo's `.gitignore` (or documented as a user setup step) to prevent runtime data from being committed.

### Cross-Cutting: Project Config File

`.clean_room/config.toml` stores project-level settings and is created by `cra init`. In the active development plan, required runtime inputs remain explicit at call sites (no fallback loading from config for required values).

```toml
[model]
name = "deepseek-coder:33b"       # --model flag
base_url = "http://localhost:11434" # --base-url flag

[budget]
context_window = 32768             # --context-window flag
reserved_tokens = 4096             # --reserved-tokens flag

[solve]
max_attempts = 3                   # --max-attempts flag
max_refinement_loops = 2           # --max-refinement-loops flag
```

- `cra init` creates the config interactively or from explicit flags. It does not populate values the user does not provide.
- `cra retrieve` and `cra solve` require explicit runtime inputs for required values; they do not silently fill missing required values from `.clean_room/config.toml`.
- Config loading is a thin utility (`config.py`), not a framework. Reads TOML and returns a flat dict.
- The `--budget-config` flag (Phase 2/3) is an explicit input mechanism for sharing budget values between tools.

